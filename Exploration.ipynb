{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\eagle\\anaconda3\\lib\\site-packages (0.1.59)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from yfinance) (0.0.9)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from yfinance) (1.19.2)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from yfinance) (2.24.0)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from yfinance) (4.6.1)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from yfinance) (1.1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas>=0.24->yfinance) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Collecting pandas_datareader\n",
      "  Downloading pandas_datareader-0.9.0-py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas_datareader) (1.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas_datareader) (2.24.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas_datareader) (4.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (1.19.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eagle\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas_datareader) (1.15.0)\n",
      "Installing collected packages: pandas-datareader\n",
      "Successfully installed pandas-datareader-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all-trans-5-4-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['asset_description','comment','ptr_link']\n",
    "columns_list = data.columns.values.tolist() #list of all columns\n",
    "for i in range(len(columns_list)): #columns in table\n",
    "    if columns_list[i] in drops: #if one of the variables we don't care about\n",
    "        data.pop(columns_list[i]) #remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data['asset_type'] != \"Stock\"].index, inplace = True) #remove all non stocks from the list of assets\n",
    "data.drop(data[data['type'] != \"Purchase\"].index, inplace = True) #remove all non purchases from the list of types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splice_date(date):\n",
    "    date_to_list = list(date)\n",
    "    date_to_string = \"\"\n",
    "    for i in range(len(date_to_list)):\n",
    "        if date_to_list[i] == '/':\n",
    "            date_to_list[i] = '-'\n",
    "    for i in range(len(date_to_list)):\n",
    "        date_to_string = date_to_string + date_to_list[i]\n",
    "    return date_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[2400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timelines():\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    trans_prices = []\n",
    "    two_month_changes = [] #lists of the changes over each time period\n",
    "    four_month_changes = []\n",
    "    eight_month_changes = []\n",
    "    one_year_changes = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for r,c in test.iterrows(): #iterate over the cases\n",
    "        if i % 100 == 0:\n",
    "            print(str(i)+\" entries have been analyzed.\")\n",
    "        date = splice_date(c['transaction_date']) #index into the transaction date variable and splice it to work within the api\n",
    "        ticker = c['ticker'] #grab the ticker symbol\n",
    "        try: \n",
    "            stock_data = pdr.get_data_yahoo(ticker, start=date)\n",
    "            trans_price = round(stock_data.iloc[0,2],3)\n",
    "            two_month_change = round(stock_data.iloc[60,5] - stock_data.iloc[0,2],3)\n",
    "            four_month_change = round(stock_data.iloc[120,5] - stock_data.iloc[0,2],3)\n",
    "            eight_month_change = round(stock_data.iloc[240,5] - stock_data.iloc[0,2],3)\n",
    "            one_year_change = round(stock_data.iloc[365,5] - stock_data.iloc[0,2],3)\n",
    "            trans_prices.append(trans_price)\n",
    "            two_month_changes.append(two_month_change)\n",
    "            four_month_changes.append(four_month_change)\n",
    "            eight_month_changes.append(eight_month_change)\n",
    "            one_year_changes.append(one_year_change)\n",
    "        except:\n",
    "            NA = 'NA'\n",
    "            trans_prices.append(NA)\n",
    "            two_month_changes.append(NA)\n",
    "            four_month_changes.append(NA)\n",
    "            eight_month_changes.append(NA)\n",
    "            one_year_changes.append(NA)\n",
    "        i+=1\n",
    "        if i == test.shape[0]:\n",
    "            break\n",
    "    \n",
    "    test['_transaction_price'] = trans_prices\n",
    "    test['_60_days'] = two_month_changes\n",
    "    test['_120_days'] = four_month_changes\n",
    "    test['_240_days'] = eight_month_changes\n",
    "    test['_365_days'] = one_year_changes\n",
    "    \n",
    "    \n",
    "    test.drop(test[test['_transaction_price'] == \"NA\"].index, inplace = True) #remove all assets that don't have a value so they arent searched for in the future\n",
    "    test.drop(test[test['_60_days'] == \"NA\"].index, inplace = True) #remove all assets that don't have a value so they arent searched for in the future\n",
    "    test.drop(test[test['_120_days'] == \"NA\"].index, inplace = True) #remove all assets that don't have a value so they arent searched for in the future\n",
    "    test.drop(test[test['_240_days'] == \"NA\"].index, inplace = True) #remove all assets that don't have a value so they arent searched for in the future\n",
    "    test.drop(test[test['_365_days'] == \"NA\"].index, inplace = True) #remove all assets that don't have a value so they arent searched for in the future\n",
    "    \n",
    "    print(\"Done with Data Gathering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 entries have been analyzed.\n",
      "100 entries have been analyzed.\n",
      "200 entries have been analyzed.\n",
      "300 entries have been analyzed.\n",
      "400 entries have been analyzed.\n",
      "500 entries have been analyzed.\n",
      "600 entries have been analyzed.\n",
      "700 entries have been analyzed.\n"
     ]
    }
   ],
   "source": [
    "get_timelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(20)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('500_trans_with_labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
